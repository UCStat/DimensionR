---
title: "Numerical Illustration"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---



```{r, warning=FALSE, message=FALSE}
#we load the packages
library(tidyverse)
library('corrr')
library(ggcorrplot)
library("FactoMineR")
library("devtools")
library(MASS)
library(caret)
library("factoextra")
library(pls)
library(ISLR)
library(class)
library(kknn)
library(laGP)
library(plgp)
library(GenSA)
library(concordance)
```




```{r}

#We compute the proportion of variation explained by the PCA's for the AS
 ProVariation = function(eignevalues){
   proVar=rep(NA, 10)
 eig=eignevalues
 for (l in 1:length(eignevalues)) {
   initV=eig[1]/sum(eig)
   nextV= sum(eig[1:l])/sum(eig)
   proVar[l]=nextV
 }
 return(proVar)
 }

 

#saparable or anisotropic Gaussian family
eps <- sqrt(.Machine$double.eps)

nlsep <- function(par, X, Y)
{
theta <- par[1:ncol(X)]
g <- par[ncol(X)+1]
n <- length(Y)
K <- covar.sep(X, d=theta, g=g)
Ki <- solve(K)
ldetK <- determinant(K, logarithm=TRUE)$modulus
ll <- - (n/2)*log(t(Y) %*% Ki %*% Y) - (1/2)*ldetK
counter <<- counter + 1
return(-ll)
}



gradnlsep <- function(par, X, Y)
{
theta <- par[1:ncol(X)]
g <- par[ncol(X)+1]
n <- length(Y)
K <- covar.sep(X, d=theta, g=g)
Ki <- solve(K)
KiY <- Ki %*% Y
## loop over theta components
dlltheta <- rep(NA, length(theta))
for(k in 1:length(dlltheta)) {
dotK <- K * distance(X[,k])/(theta[k]^2)
dlltheta[k] <- (n/2) * t(KiY) %*% dotK %*% KiY / (t(Y) %*% KiY) -
(1/2)*sum(diag(Ki %*% dotK))
}

## for g
dllg <- (n/2) * t(KiY) %*% KiY / (t(Y) %*% KiY) - (1/2)*sum(diag(Ki))
return(-c(dlltheta, dllg))
}


scoreV <- function(Y, mu, Sigma, Sigmai)
{
Ymmu <- Y - mu
mahdist <- t(Ymmu) %*% Sigmai %*% Ymmu

return (- determinant(Sigma, logarithm=TRUE)$modulus - mahdist)
}


# X=DataAct2[, -1] %>% as.matrix();
# y=Datatrain2[, 1] %>% as.matrix();
# XX=Acttest2 %>% as.matrix();
# yytrue=Datatest2[, 1] %>% as.matrix()
#tic <- proc.time()[3]

DimRed = function(X, y, XX, yytrue){


outg <- optim(c(rep(0.1, ncol(X)), 0.1*var(y)), nlsep,gradnlsep,
method="L-BFGS-B", lower=eps, upper=c(rep(Inf, ncol(X)), var(y)), X=X, Y=y)


K <- covar.sep(X, d=outg$par[1:ncol(X)], g=outg$par[ncol(X)+1])
Ki <- solve(K)
tau2hat <- drop(t(y) %*% Ki %*% y / nrow(X))
KXX <- covar.sep(XX, d=outg$par[1:ncol(X)], g=outg$par[ncol(X)+1])
KX <- covar.sep(XX, X, d=outg$par[1:ncol(X)], g=0)
mup2 <- KX %*% Ki %*% y
Sigmap2 <- tau2hat*(KXX - KX %*% Ki %*% t(KX))

Ymmu <- yytrue - mup2
Sigmai <- solve(Sigmap2)


#Different comparison metric 

#Root-mean-square error
RMSPE=sqrt(mean(Ymmu^2))

#Root mean square error adjusted by covariance
mahdist <- t(Ymmu) %*% Sigmai %*% Ymmu
RMSPE_adj_cov=sqrt(mahdist)


#Score which gives account of the magnitude of uncertainty and error accounted by the prediction
#score_value= -determinant(Sigmap2, logarithm=TRUE)$modulus - mahdist
score_value <- scoreV(Y=yytrue, mu=mup2, Sigma=Sigmap2, Sigmai=Sigmai)

#Normalized predictive root-mean-square-error(PRMSE)
Normalized_PRMSE=RMSPE/(max(y)-min(y))

#we compute NSME
Nnsme = sum(Ymmu^2)
Dnsme = sum((yytrue-mean(yytrue))^2)
NSME = 1-(Nnsme/Dnsme)

#Compute the nominal coverage
lowerC = mup2 - 1.96 * sqrt(diag(Sigmap2) %>% as.matrix())
upperC = mup2 +  1.96 * sqrt(diag(Sigmap2) %>% as.matrix())
#if((lowerC <= yytrue) & (yytrue <= upperC)){
 # answerYes =1
#}else{
  #answer=0
  #}
inside_interval <- (lowerC <= yytrue) & (yytrue <= upperC)
coverage_prob <- mean(inside_interval)


# 95% ALCI 
average_length <- mean(upperC - lowerC)

#Continuous Ranked Probability Score
# Assuming you have mean and standard deviation for each observation
mean_values <- mup2 %>% as.vector()  # Replace with your mean values
std_dev_values <-sqrt(diag(Sigmap2))  # Replace with your standard deviation values
observed_values <- yytrue %>% as.vector()  # Replace with your observed values

# Function to calculate predicted CDF for a normal distribution
calculate_normal_cdf <- function(mean, std_dev, x) {
pnorm(x, mean, std_dev)
}

# Calculate predicted CDF for each observation
predicted_cdf <- sapply(1:length(mean_values), function(i) {
calculate_normal_cdf(mean=mean_values[i], std_dev=std_dev_values[i], x=observed_values[i])
})
# Replace this with the range of values for which you want to compute the CDF
compute_crps <- function(observed, mean, std_dev) {
if (any(is.na(observed)) || any(is.na(mean)) || any(is.na(std_dev))) {
    stop("Input vectors contain NA values.")
  }
  
  if (any(is.infinite(observed)) || any(is.infinite(mean)) || any(is.infinite(std_dev))) {
    stop("Input vectors contain infinite values.")
  }

  if (length(observed) != length(mean) || length(observed) != length(std_dev)) {
    stop("Lengths of input vectors do not match.")
  }
  
  
num_obs <- length(observed)
crps_values <- numeric(num_obs)
for (i in 1:num_obs) {
    obs_i <- observed[i]
    predicted_cdf <- calculate_normal_cdf(mean[i], std_dev[i], obs_i)
    crps_values[i] <- (predicted_cdf - (obs_i <= mean[i]))^2
  }

  return(mean(crps_values))
}

# Compute CRPS
crps_score <- compute_crps(observed=observed_values, mean=mean_values, std_dev=std_dev_values)


# metric=c(RMSPE=RMSPE,NSME=NSME,coverage_prob=coverage_prob, 
#          ALCI=average_length, CRPS=crps_score, RMSPE_adj_cov=RMSPE_adj_cov,  
#          Normalized_PRMSE=Normalized_PRMSE, m_uncertainty=-determinant(Sigmap2, logarithm=TRUE)$modulus, 
#          score_value=score_value)

metric=c(RMSPE=RMSPE,NSME=NSME,coverage_prob=coverage_prob, 
         ALCI=average_length, CRPS=crps_score,  
         score_value=score_value)

return(metric)

}

# mylhs <- function(n, d)
# {
# ## generate the Latin hypercube
# l <- (-(n - 1)/2):((n - 1)/2)
# L <- matrix(NA, nrow=n, ncol=d)
# for(j in 1:d) L[,j] <- sample(l, n)
# ## draw the random uniforms and turn the hypercube into a sample
# U <- matrix(runif(n*d), ncol=d)
# X <- (L + (n - 1)/2 + U)/n
# colnames(X) <- paste0("x", 1:d)
# ## return the design and the grid it lives on for visualization
# return(X=X)
# }


# mymaximin <- function(n, m, T=100000)
# {
# X <- matrix(runif(n*m), ncol=m) ## initial design
# d <- distance(X)
# d <- d[upper.tri(d)]
# md <- min(d)
# for(t in 1:T) {
# row <- sample(1:n, 1)
# xold <- X[row,] ## random row selection
# X[row,] <- runif(m) ## random new row
# d <- distance(X)
# d <- d[upper.tri(d)]
# mdprime <- min(d)
# if(mdprime > md) { md <- mdprime ## accept
# } else { X[row,] <- xold } ## reject
# }
# return(X)
# }

# mymaximinP <- function(n, m, T=100000, Xorig=NULL)
# { X <- matrix(runif(n*m), ncol=m) ## initial design
# d <- distance(X); d <- d[upper.tri(d)];
# md <- min(d)
# if(!is.null(Xorig)) { ## new code
# md2 <- min(distance(X, Xorig))
# if(md2 < md) md <- md2
# }
# for(t in 1:T) {
# row <- sample(1:n, 1)
# xold <- X[row,] ## random row selection
# X[row,] <- runif(m) ## random new row
# d <- distance(X); d <- d[upper.tri(d)]; mdprime <- min(d);
# if(!is.null(Xorig)) { ## new code
# mdprime2 <- min(distance(X, Xorig))
# if(mdprime2 < mdprime) mdprime <- mdprime2
# }
# if(mdprime > md) { md <- mdprime ## accept
# } else { X[row,] <- xold } ## reject
# }
# return(X)
# }



# function to obtain our data
fried <- function(n=200, d=10, a, b, Gamma, B_0, e){
 #Xd<-randomLHS(10, d)
#Xd<-mylhs(n, d)
#Xd = mymaximinP(n-10, d, T=100000, Xorig=Xdd)
#Xd=rbind(Xdd, Xd)
Xd<-mvrnorm(n, rep(0, d),  diag(10))
Z = Xd %*% B_0
Ytrue<-a*matrix(rep(1, n), nrow = n) + b*Z + Gamma *  Z^2  
Y<-Ytrue + e
data=data.frame(Xd, Y, Ytrue)
ntr2= n *0.8
nte2= n *0.2
X <- as.matrix(data[1:ntr2,1:d])
y <- drop(data$Y[1:ntr2])
ytr <- drop(data$Ytrue[1:ntr2])
XX <- as.matrix(data[(ntr2 + 1):n,1:d])
yy <- drop(data$Y[(ntr2 + 1):n])
yytrue <- drop(data$Ytrue[(ntr2 + 1):n])
datatrain<-data.frame(X, y)
datatest<-data.frame(XX, yy)
return(list(data=data,datatrain=datatrain,datatest=datatest, yytrue=yytrue, trainX=X, trainY=ytr %>% as.matrix(), testX=XX, testY=Ytrue %>% as.matrix()))
}


Frobenius_norm =function(A){
 D=ncol(A)
 d=nrow(A)
 Fnorm=0
 for(i in 1:d){
   for(j in 1:D){
     Fnorm = Fnorm + (A[i, j])^2
   }
   
 }
  
 return(sqrt(Fnorm))

}

#By Kenji Fukumizu, Francis R. Bach and Michael I. Jordan
#KERNEL DIMENSION REDUCTION IN REGRESSION
kernel_method = function(W, W_0){
  
  Discrep= W_0 %*% t(W_0) -  W %*% t(W) 
  
  return(Frobenius_norm(Discrep))
}

# W=simPls4$projection[, 1] %>% as.matrix()
# W_0=B
#Kenji Fukumizu and Chenlei Leng 2013
#Gradient-based kernel dimension reduction for regression
gKDR_method = function(W, W_0){
  D=ncol(W)
  d=nrow(W)
  
  #if(D=1)
  Discrep =  W_0 %*% t(W_0)  %*% (diag(d) - W %*% t(W))
  
  return(Frobenius_norm(Discrep)/sqrt(D))
}


#Li, Zha, and Chiaromonte,2005
#Contour regression: a general approach to dimension reduction
Li_and_Chiaromonte_method= function(W, W_0){
  
  P_0 = W_0 %*% solve(t(W_0) %*% W_0) %*% t(W_0) 
  P = W %*% solve(t(W) %*% W) %*% t(W) 
  
  return(sum(diag((P-P_0) %*% (P-P_0))))
}


#B. Li and S. Wang. 2007
#On directional regression for dimension reduction

Wang_method= function(W, W_0){
  
  P_0 = W_0 %*% solve(t(W_0) %*% W_0) %*% t(W_0) 
  P = W %*% solve(t(W) %*% W) %*% t(W) 
  
  return(Frobenius_norm((P-P_0) %*% (P-P_0)))
}


#FerrÂ´e, L. (1998), 
#Determining the dimension in sliced inverse 
# W=resultsPCA2$rotation[, 1:8]
# W_0=B
Ferr_method = function(W, W_0){
  D=ncol(W_0)
  Discrep=solve(t(W_0) %*% W_0) %*% (t(W_0) %*% W) %*% (solve(t(W) %*% W) %*% (t(W) %*% W_0) )
  
  return(sum(diag(Discrep))/D)
}

#Pal, S.; Sengupta, S.; Mitra, R.; Banerjee, A. 
#Conjugate Priors and Posterior Inference for the Matrix Langevin Distribution on the Stiefel Manifold.

Relative_error = function(W, W_0){
  DW=W - W_0
  Frob_D = Frobenius_norm(DW)
  Frob_W_0 = Frobenius_norm(W_0)
  rlative=Frob_D/Frob_W_0
  
  return(rlative)
} 


```



```{r}

#Simulate data
set.seed(1000)

d=10

N=c(150, 350, 600)

b1 = c(-0.0091, -0.0579, -0.1877, 0.4774, 0.4559, -0.6714, -0.1264, -0.0082, 0.0724, -0.2308)

a = -0.16113;
b= -0.97483;
Gamma = -1.66526

B = matrix(b1, nrow = d, ncol = 1)



#Perturbation
e2=matrix(rnorm(N[1],0, 0.1^2), nrow = N[1])
e4=matrix(rnorm(N[2], 0, 0.1^2), nrow = N[2])
e6=matrix(rnorm(N[3], 0, 0.1^2), nrow = N[3])


Data2=fried(n=N[1],d=10, a=a, b=b, Gamma=Gamma, B_0=B, e=e2)
Data4=fried(n=N[2],d=10, a=a, b=b, Gamma=Gamma, B_0=B, e=e4)
Data6=fried(n=N[3],d=10, a=a, b=b, Gamma=Gamma, B_0=B, e=e6)

write.csv(Data2$trainX, file="trainX22.csv", row.names = FALSE)
write.csv(Data2$trainY, file="trainY22.csv", row.names = FALSE)
#write.csv(Data2$testX, file="testX2.csv", row.names = FALSE)
#write.csv(Data2$testY, file="testY2.csv", row.names = FALSE)


write.csv(Data4$trainX, file="trainX44.csv", row.names = FALSE)
write.csv(Data4$trainY, file="trainY44.csv", row.names = FALSE)
#write.csv(Data4$testX, file="testX4.csv", row.names = FALSE)
#write.csv(Data4$testY, file="testY4.csv", row.names = FALSE)


write.csv(Data6$trainX, file="trainX66.csv", row.names = FALSE)
write.csv(Data6$trainY, file="trainY66.csv", row.names = FALSE)
#write.csv(Data6$testX, file="testX6.csv", row.names = FALSE)
#write.csv(Data6$testY, file="testY6.csv", row.names = FALSE)
```









# PCA

```{r}


set.seed(1000)
# A case of using 120 training size
tic <- proc.time()[3]
resultsPCA2 <- prcomp(Data2$datatrain[, -11], scale = TRUE)
summary(resultsPCA2)
fviz_eig(resultsPCA2,
         addlabels = TRUE,
         choice="eigenvalue") +
         geom_hline(yintercept=1,
     linetype="dashed",
         color = "red")
toc <- proc.time()[3]
toc - tic

#graph_eigen((resultsPCA2$sdev)^2)

# fviz_eig(resultsPCA2 , 
#          addlabels = TRUE, 
#          ylim = c(0, 70),
#          main="Figure 5: Scree Plot")


# A case of using 280 training size
tic <- proc.time()[3]
resultsPCA4 <- prcomp(Data4$datatrain[, -11], scale = TRUE)
fviz_eig(resultsPCA4,
         addlabels = TRUE,
         choice="eigenvalue") +
         geom_hline(yintercept=1,
         linetype="dashed",
         color = "red")
summary(resultsPCA4)
toc <- proc.time()[3]
toc - tic

#graph_eigen((resultsPCA4$sdev)^2)


# A case of using 480 training size
tic <- proc.time()[3]
resultsPCA6 <- prcomp(Data6$datatrain[, -11], scale = TRUE)
fviz_eig(resultsPCA6,
         addlabels = TRUE,
         choice="eigenvalue") +
         geom_hline(yintercept=1,
         linetype="dashed",
         color = "red")
summary(resultsPCA6)
toc <- proc.time()[3]
toc-tic

#graph_eigen((resultsPCA6$sdev)^2)
```


# PLS

```{r}

set.seed(1000)

# A case of using 120 training size
tic <- proc.time()[3]
simPls2 <- plsr(y ~ . , ncomp = 10, data = Data2$datatrain %>% as.data.frame(),  
                scale = TRUE, validation = "LOO")
summary(simPls2)
plot(RMSEP(simPls2))
cv2=RMSEP(simPls2)
adjcv2=cv2$val[estimate= "adjCV", , ][-1] %>% as.vector()
best.dims2 <- which.min(cv2$val[estimate= "adjCV", , ]) - 1
best.dims2
toc <- proc.time()[3]
toc - tic


# A case of using 280 training size
tic <- proc.time()[3]
simPls4 <- plsr(y ~ . , ncomp = 10, data = Data4$datatrain %>% as.data.frame(),
                scale = TRUE, validation = "LOO")
summary(simPls4)
plot(RMSEP(simPls4))
cv4=RMSEP(simPls4)
adjcv4=cv4$val[estimate= "adjCV", , ][-1] %>% as.vector()
best.dims4 <- which.min(cv4$val[estimate= "adjCV", , ]) - 1
best.dims4
toc <- proc.time()[3]
toc -tic

# A case of using 480 training size
tic <- proc.time()[3]
simPls6 <- plsr(y ~ . , ncomp = 10, data = Data6$datatrain %>% as.data.frame(),
                scale = TRUE, validation = "LOO")
summary(simPls6)
plot(RMSEP(simPls6))
cv6=RMSEP(simPls6)
adjcv6=cv6$val[estimate= "adjCV", , ][-1] %>% as.vector()
best.dims6 <- which.min(cv6$val[estimate= "adjCV", , ]) - 1
best.dims6
toc <- proc.time()[3]
toc - tic
```



# AS

```{r}
# Define the function to calculate gradient
compute_gradient <- function(x, W, Beta, F) {
  Beta_W_T <- as.vector(t(Beta) %*% t(W))  # Ensure proper dimensions
  W_F_W_T <- 2 * W %*% F %*% t(W)          # Correct matrix multiplication
  gradient <- Beta_W_T + W_F_W_T %*% x     # Combine results
  return(gradient)
}

# Calculate the gradient and H_hat
calculate_H_hat <- function(X, W, Beta, F) {
  n <- nrow(X)
  p <- ncol(X)
  
  # Initialize H_hat
  H_hat <- matrix(0, nrow = p, ncol = p)
  grad_hat <- matrix(0, nrow = n, ncol = p)
  
  for (i in 1:n) {
    x_i <- matrix(X[i, ], ncol = 1)  # Ensure x_i is a column vector
    grad_y_i <- compute_gradient(x_i, W, Beta, F)
    H_hat <- H_hat + grad_y_i %*% t(grad_y_i)
    grad_hat[i, ] = grad_y_i 
  }
  
  H_hat <- H_hat / n
  cov_grad= cov(grad_hat)
  return(list(H_hat=H_hat, cov_grad=cov_grad, grad_hat=grad_hat))
}


X22=Data2$datatrain[, -11] %>% as.matrix()
X44=Data4$datatrain[, -11] %>% as.matrix()
X66=Data6$datatrain[, -11] %>% as.matrix()

```


```{r}
set.seed(1000)

# A case of using 120 training size
tic <- proc.time()[3]
ras_result2 <- calculate_H_hat(X=Data2$datatrain[, -11] %>% as.matrix(), W=B, Beta=b, F=Gamma)
DecompC2=eigen(ras_result2$H_hat)
W2=DecompC2$vectors %>% as.matrix()
toc <- proc.time()[3]
toc-tic
DecompC22=svd(ras_result2$grad_hat)
W22=DecompC22$v %>% as.matrix()


# A case of using 280 training size
tic <- proc.time()[3]
ras_result4 <- calculate_H_hat(X=Data4$datatrain[, -11] %>% as.matrix(), W=B, Beta=b, F=Gamma)
DecompC4=eigen(ras_result4$H_hat)
W4=DecompC4$vectors %>% as.matrix()
toc <- proc.time()[3]
toc-tic
DecompC44=svd(ras_result4$grad_hat)
W44=DecompC44$v %>% as.matrix()


# A case of using 480 training size
tic <- proc.time()[3]
ras_result6 <- calculate_H_hat(X=Data6$datatrain[, -11] %>% as.matrix(), W=B, Beta=b, F=Gamma)
DecompC6=eigen(ras_result6$H_hat)
W6=DecompC6$vectors %>% as.matrix()
toc <- proc.time()[3]
toc-tic
DecompC66=svd(ras_result6$grad_hat)
W66=DecompC66$v %>% as.matrix()


```



```{r}

# Codes for the plots
# Load the ggplot2 library
library(ggplot2)

graph_eigenA <- function(eigenvalues, size) {
  library(ggplot2)
  library(ggrepel)
  
  # Calculate cumulative sum and convert to percentage of total
  eigenvalues_df <- data.frame(
    Eigenvalue = eigenvalues,
    Component = 1:length(eigenvalues)
  )
  eigenvalues_df$CumulativePercentage <- cumsum(eigenvalues_df$Eigenvalue) / sum(eigenvalues_df$Eigenvalue) * 100
  
  # Create a scree plot with optimized y-axis and label placements
  scree_plot <- ggplot(eigenvalues_df, aes(x = Component, y = CumulativePercentage)) +
    geom_line() +  # Add a line graph
    geom_point() +  # Add points to the graph
    geom_text_repel(  # Use ggrepel for better label management
      aes(label = sprintf("%.2f%%", CumulativePercentage)),
      nudge_y = 2,  # Nudge labels upward for clarity
      size = 5,  # Increase text size
      box.padding = unit(0.35, "lines"),  # Add padding around text
      point.padding = unit(0.3, "lines")  # Add padding around points
    ) +
    labs(x = "Principal Component",
         y = "Cumulative Percentage (%)") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
      axis.text = element_text(size = size),  # Increase axis text size
      axis.title = element_text(size = size)  # Increase axis title size
    ) +
    scale_x_continuous(breaks = 1:10, labels = 1:10) +  # Define x-axis breaks and labels from 1 to 10
    scale_y_continuous(limits = c(10, 105), expand = c(0, 0))  # Adjust y-axis to show 0% to slightly above 100%
  
  # Display the plot
  return(print(scree_plot))
}


graph_eigenA((resultsPCA2$sdev)^2, size=22)
graph_eigenA((resultsPCA4$sdev)^2, size=22)
graph_eigenA((resultsPCA6$sdev)^2, size=22)



# Create a data frame with your data
c2=cv2$val[estimate= "adjCV", , ] %>% as.vector()
data2 <- data.frame(
  Component = 1:10,  # Principal Components from 1 to 10
  CV_error = c2[-1]# Your data points
)

# Create the plot
plot2 <- ggplot(data2, aes(x = Component, y = CV_error)) +
  geom_line() +  # Connect points with a line
  geom_point() +  # Show points on the plot
  labs(x = "Component", y = "LOOCV Error") +
  theme_minimal() +  # Use a minimal theme
  theme(
    axis.text = element_text(size = 22),  # Increase the axis numbering size
    axis.title = element_text(size = 22)  # Adjust this size if needed
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10)
# Print the plot
print(plot2)




# Create a data frame with your data
c4=cv4$val[estimate= "adjCV", , ] %>% as.vector()
data4 <- data.frame(
  Component = 1:10,  # Principal Components from 1 to 10
  CV_error = c4[-1]# Your data points
)

# Create the plot
plot4 <- ggplot(data4, aes(x = Component, y = CV_error)) +
  geom_line() +  # Connect points with a line
  geom_point() +  # Show points on the plot
  labs(x = "Component", y = "LOOCV Error") +
  theme_minimal() +  # Use a minimal theme
  theme(
    axis.text = element_text(size = 22),  # Increase the axis numbering size
    axis.title = element_text(size = 22)  # Adjust this size if needed
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10)
# Print the plot
print(plot4)




# Create a data frame with your data
c6=cv6$val[estimate= "adjCV", , ] %>% as.vector()
data6 <- data.frame(
  Component = 1:10,  # Principal Components from 1 to 10
  CV_error = c6[-1]# Your data points
)

# Create the plot
plot6 <- ggplot(data6, aes(x = Component, y = CV_error)) +
  geom_line() +  # Connect points with a line
  geom_point() +  # Show points on the plot
  labs(x = "Component", y = "LOOCV Error") +
  theme_minimal() +  # Use a minimal theme
  theme(
    axis.text = element_text(size = 22),  # Increase the axis numbering size
    axis.title = element_text(size = 22)  # Adjust this size if needed
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10)
# Print the plot
print(plot6)

# 


library(ggrepel)  # For better label placement

graph_eigenA1=function(eigenvalues){
  # Calculate cumulative sum and convert to percentage of total
  eigenvalues_df <- data.frame(
    Eigenvalue = eigenvalues,
    Component = 1:length(eigenvalues)
  )
  eigenvalues_df$CumulativePercentage <- cumsum(eigenvalues_df$Eigenvalue) / sum(eigenvalues_df$Eigenvalue) * 100
  
  # Create a scree plot with optimized y-axis and label placements
  scree_plot <- ggplot(eigenvalues_df, aes(x = Component, y = CumulativePercentage)) +
    geom_line() +  # Add a line graph
    geom_point() +  # Add points to the graph
    geom_text_repel(  # Use ggrepel for better label management
      aes(label = sprintf("%.2f%%", CumulativePercentage)),
      nudge_y = 2,  # Nudge labels upward for clarity
      size = 3,  # Adjust text size if necessary
      box.padding = unit(0.35, "lines"),  # Add padding around text
      point.padding = unit(0.3, "lines")  # Add padding around points
    ) +
    labs(x = "Active Component",
         y = "Cumulative Percentage (%)") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
      axis.text = element_text(size = size),  # Increase axis text size
      axis.title = element_text(size = size)  # Increase axis title size
    ) +  # Center the plot title
    scale_x_continuous(breaks = 1:10, labels = 1:10) +  # Define x-axis breaks and labels from 1 to 10
    scale_y_continuous(limits = c(60, 105), expand = c(0, 0))  # Adjust y-axis to show 0% to slightly above 100%
  
  # Display the plot
  return(print(scree_plot))
}
graph_eigenA1(DecompC2$values)
graph_eigenA1(DecompC4$values)
graph_eigenA1(DecompC6$values)

#DecompC2$values

graph_eigenA11 <- function(eigenvalues) {
  library(ggplot2)
  library(ggrepel)
  
  # Calculate cumulative sum and convert to percentage of total
  eigenvalues_df <- data.frame(
    Eigenvalue = eigenvalues,
    Component = 1:length(eigenvalues)
  )
  eigenvalues_df$CumulativePercentage <- cumsum(eigenvalues_df$Eigenvalue) / sum(eigenvalues_df$Eigenvalue) * 100
  
  # Create a scree plot with optimized y-axis and label placements
  scree_plot <- ggplot(eigenvalues_df, aes(x = Component, y = CumulativePercentage)) +
    geom_line() +  # Add a line graph
    geom_point() +  # Add points to the graph
    geom_text_repel(  # Use ggrepel for better label management
      aes(label = sprintf("%.2f%%", CumulativePercentage)),
      nudge_y = 2,  # Nudge labels upward for clarity
      size = 5,  # Increase text size
      box.padding = unit(0.35, "lines"),  # Add padding around text
      point.padding = unit(0.3, "lines")  # Add padding around points
    ) +
    labs(x = "Active Component",
         y = "Cumulative Percentage (%)") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
      axis.text = element_text(size = 22),  # Increase axis text size
      axis.title = element_text(size = 22)  # Increase axis title size
    ) +
    scale_x_continuous(breaks = 1:10, labels = 1:10) +  # Define x-axis breaks and labels from 1 to 10
    scale_y_continuous(limits = c(95, 105), expand = c(0, 0))  # Adjust y-axis to show 0% to slightly above 100%
  
  # Display the plot
  return(print(scree_plot))
}


graph_eigenA11(DecompC2$values)
graph_eigenA11(DecompC4$values)
graph_eigenA11(DecompC6$values)



library(ggplot2)
library(reshape2)
library(patchwork)  # Load patchwork for arranging plots

# # Data Preparation
# gKDR1 <- c(0.145368, 0.351702, 0.550187, 0.602102, 0.751283, 0.811140, 0.833401, 0.834410, 0.850487, 0.997203)
# gKDRi1 <- c(0.012736, 0.014167, 0.129851, 0.163107, 0.203299, 0.378923, 0.451970, 0.556865, 0.58880, 0.816915)
# gKDRV1 <- c(0.0168779, 0.023767, 0.030907, 0.176721, 0.288112, 0.530105, 0.621648, 0.772810, 0.919913, 0.964612)
# gKDRV1_r<-c(0.01537, 0.167506, 0.382841, 0.583909,0.599502, 0.776984, 0.837549, 0.942338, 0.955621, 0.999128)
# 
# gKDR2 <- c(0.128234, 0.266175, 0.447402, 0.688966, 0.697123, 0.766374, 0.826656, 0.903368, 0.976219, 0.980084)
# gKDRi2 <- c(0.005279, 0.025839, 0.183788, 0.197487, 0.214113, 0.253439, 0.287174, 0.420978, 0.653121, 0.879273642)
# gKDRV2 <- c(0.0076243, 0.0536932, 0.0170953, 0.197535, 0.227500, 0.279711, 0.287552, 0.460171, 0.516762, 0.949253)
# gKDRV2_r<- c(0.0103, 0.154216, 0.302267, 0.475749, 0.514529,0.752811, 0.803357, 0.855109, 0.899559, 0.998177)
# 
# gKDR3 <- c(0.030334, 0.057870, 0.117302, 0.144144, 0.178462, 0.478287, 0.547125, 0.801500, 0.844774, 0.997859)
# gKDRi3 <- c(0.001367, 0.013756, 0.014295, 0.160517, 0.216903, 0.234015, 0.260288, 0.3682068, 0.5679432, 0.7882854)
# gKDRV3 <- c(0.004979, 0.065420, 0.156806, 0.360120, 0.379671, 0.557195, 0.625408, 0.632381, 0.803013, 0.956592)
# gKDRV3_r <- c(0.00114, 0.085557, 0.140078, 0.4074847, 0.595176, 0.61061, 0.76213, 0.839621, 0.908737, 0.999972)



# Combining data into a data frame
data <- data.frame(Index = 1:10,
                   gKDR1 = gKDR_c1,
                   gKDRi1 = gKDRi_c1,
                   gKDRV1 = gKDRv_c1,
                   gKDR2 = gKDR_c2,
                   gKDRi2 = gKDRi_c2,
                   gKDRV2 = gKDRv_c2,
                   gKDR3 = gKDR_c3,
                   gKDRi3 = gKDRi_c3,
                   gKDRV3 = gKDRv_c3)

# Melting data for ggplot
data_melted <- melt(data, id.vars = "Index")



labels <- c(gKDR1 = "gKDR", gKDRi1 = "gKDR-i", gKDRV1 = "gKDR-v",
            gKDR2 = "gKDR", gKDRi2 = "gKDR-i", gKDRV2 = "gKDR-v",
            gKDR3 = "gKDR", gKDRi3 = "gKDR-i", gKDRV3 = "gKDR-v")


P1 <- ggplot(data = subset(data_melted, variable %in% c("gKDR1", "gKDRi1", "gKDRV1")), aes(x = Index, y = value, linetype = variable)) +
  geom_line() +
  geom_point() +
  scale_linetype_manual(values = c("solid", "dashed", "dotted"), labels = labels) +
  ylab("RMSPE") +
  xlab("D") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
    axis.text = element_text(size = 11),  # Increase axis text size
    axis.title = element_text(size = 11)  # Increase axis title size
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10) +
  guides(linetype = guide_legend(title = "Method (n=120)"))+  # Define x-axis breaks and labels from 1 to 10
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) 

P2 <- ggplot(data = subset(data_melted, variable %in% c("gKDR2", "gKDRi2", "gKDRV2")), aes(x = Index, y = value, linetype = variable)) +
  geom_line() +
  geom_point() +
  scale_linetype_manual(values = c("solid", "dashed", "dotted"), labels = labels) +
  ylab("RMSPE") +
  xlab("D") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
    axis.text = element_text(size = 11),  # Increase axis text size
    axis.title = element_text(size = 11)  # Increase axis title size
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10) +
  guides(linetype = guide_legend(title = "Method (n=280)"))+  # Define x-axis breaks and labels from 1 to 10
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) 

P3 <- ggplot(data = subset(data_melted, variable %in% c("gKDR3", "gKDRi3", "gKDRV3")), aes(x = Index, y = value, linetype = variable)) +
  geom_line() +
  geom_point() +
  scale_linetype_manual(values = c("solid", "dashed", "dotted"), labels = labels) +
  ylab("RMSPE") +
  xlab("D") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),  # Increase title size
    axis.text = element_text(size = 11),  # Increase axis text size
    axis.title = element_text(size = 11)  # Increase axis title size
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10) + 
  guides(linetype = guide_legend(title = "Method (n=480)"))+  # Define x-axis breaks and labels from 1 to 10
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) 

# Combining the plots
combined_plot <- P1 + P2 + P3 + plot_layout(ncol = 1)  # Arrange vertically in one column
print(combined_plot)





graph_gKDR=function(error_value){
data <- data.frame(
  Component = 1:10,  # Principal Components from 1 to 10
  RMSPE = error_value# Your data points
)

# Create the plot
plot <- ggplot(data, aes(x = Component, y = RMSPE)) +
  geom_line() +  # Connect points with a line
  geom_point() +  # Show points on the plot
  labs(x = "D", y = "RMSPE") +
  theme_minimal() +  # Use a minimal theme
  theme(
    axis.text = element_text(size = 22),  # Increase the axis numbering size
    axis.title = element_text(size = 22)  # Adjust this size if needed
  ) +
  scale_x_continuous(breaks = 1:10, labels = 1:10)
# Print the plot
return(print(plot))
}

graph_gKDR(gKDR1)
graph_gKDR(gKDR2)
graph_gKDR(gKDR3)

graph_gKDR(gKDRi1)
graph_gKDR(gKDRi2)
graph_gKDR(gKDRi3)

graph_gKDR(gKDRV1)
graph_gKDR(gKDRV2)
graph_gKDR(gKDRV3)

graph_gKDR(gKDRV1_r)
graph_gKDR(gKDRV2_r)
graph_gKDR(gKDRV3_r)

```






```{r}
#gKDR Results

g2data =read.csv("project2Ng.csv") %>% as.matrix()
g4data =read.csv("project4Ng.csv") %>% as.matrix()
g6data =read.csv("project6Ng.csv") %>% as.matrix()

gi2data =read.csv("project2Ngi.csv")%>% as.matrix()
gi4data =read.csv("project4Ngi.csv")%>% as.matrix()
gi6data =read.csv("project6Ngi.csv")%>% as.matrix()

gv2data =read.csv("project2Ngv.csv")%>% as.matrix()
gv4data =read.csv("project4Ngv.csv")%>% as.matrix()
gv6data =read.csv("project6Ngv.csv")%>% as.matrix()

gv1_r = read.csv("W1_1.csv")%>% as.matrix()
gv2_r = read.csv("W2_1.csv")%>% as.matrix()
gv3_r = read.csv("W3_1.csv")%>% as.matrix()

```



```{r}

# We evaluate the discrepancy the estimated and true projection 

Discrepancy_PCA1 = c(Kernel=kernel_method(W=resultsPCA2$rotation[, 1:8]  %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA2$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA2$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA2$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA2$rotation[, 1:8] %>% as.matrix(), W_0=B))

Discrepancy_PCA2 = c(Kernel=kernel_method(W=resultsPCA4$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA4$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA4$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA4$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA4$rotation[, 1:8] %>% as.matrix(), W_0=B))


Discrepancy_PCA3 = c(Kernel=kernel_method(W=resultsPCA6$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA6$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA6$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA6$rotation[, 1:8] %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA6$rotation[, 1:8] %>% as.matrix(), W_0=B))


Discrepancy_PCA4 = c(Kernel=kernel_method(W=resultsPCA2$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA2$rotation[, 1:2] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA2$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA2$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA2$rotation[, 1:2]  %>% as.matrix(), W_0=B))

Discrepancy_PCA5 = c(Kernel=kernel_method(W=resultsPCA4$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA4$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA4$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA4$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA4$rotation[, 1:2]  %>% as.matrix(), W_0=B))


Discrepancy_PCA6 = c(Kernel=kernel_method(W=resultsPCA6$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=resultsPCA6$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=resultsPCA6$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=resultsPCA6$rotation[, 1:2]  %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=resultsPCA6$rotation[, 1:2]  %>% as.matrix(), W_0=B))



#PLS method
Discrepancy_PLS1 = c(Kernel=kernel_method(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B), 
                     Wang=Wang_method(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B), 
                     Ferr=Ferr_method(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B),
                     Pal=Relative_error(W=simPls2$projection[, 1] %>% as.matrix(), W_0=B))


Discrepancy_PLS2 = c(Kernel=kernel_method(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B),
                     Li=Li_and_Chiaromonte_method(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B), 
                      Wang=Wang_method(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B), 
                      Ferr=Ferr_method(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B),
                     Pal=Relative_error(W=simPls4$projection[, 1] %>% as.matrix(), W_0=B))


Discrepancy_PLS3 = c(Kernel=kernel_method(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B), 
                     gKDR_=gKDR_method(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B), 
                     Li=Li_and_Chiaromonte_method(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B), 
                      Wang=Wang_method(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B), 
                      Ferr=Ferr_method(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B),
                     Pal=Relative_error(W=simPls6$projection[, 1] %>% as.matrix(), W_0=B))




#AS
Discrepancy_AS1 = c(Kernel=kernel_method(W=W2[, 1] %>% as.matrix(), W_0=B),
                    gKDR_=gKDR_method(W=W2[, 1] %>% as.matrix(), W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=W2[, 1] %>% as.matrix(), W_0=B), 
                    Wang=Wang_method(W=W2[, 1] %>% as.matrix(), W_0=B), 
                    Ferr=Ferr_method(W=W2[, 1] %>% as.matrix(), W_0=B),
                    Pal=Relative_error(W=W2[, 1] %>% as.matrix(), W_0=B))

Discrepancy_AS2 = c(Kernel=kernel_method(W=W4[, 1] %>% as.matrix(), W_0=B),
                    gKDR_=gKDR_method(W=W4[, 1] %>% as.matrix(), W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=W4[, 1] %>% as.matrix(), W_0=B), 
                    Wang=Wang_method(W=W4[, 1] %>% as.matrix(), W_0=B), 
                    Ferr=Ferr_method(W=W4[, 1] %>% as.matrix(), W_0=B),
                    Pal=Relative_error(W=W4[, 1] %>% as.matrix(), W_0=B))

Discrepancy_AS3 = c(Kernel=kernel_method(W=W6[, 1] %>% as.matrix(), W_0=B),
                    gKDR_=gKDR_method(W=W6[, 1] %>% as.matrix(), W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=W6[, 1] %>% as.matrix(), W_0=B), 
                    Wang=Wang_method(W=W6[, 1] %>% as.matrix(), W_0=B), 
                    Ferr=Ferr_method(W=W6[, 1] %>% as.matrix(), W_0=B),
                    Pal=Relative_error(W=W6[, 1] %>% as.matrix(), W_0=B))


#gKDR

Discrepancy_g2data = c(Kernel=kernel_method(W=g2data, W_0=B),
                    gKDR_=gKDR_method(W=g2data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=g2data, W_0=B), 
                    Wang=Wang_method(W=g2data, W_0=B), 
                    Ferr=Ferr_method(W=g2data, W_0=B))

Discrepancy_g4data  = c(Kernel=kernel_method(W=g4data , W_0=B),
                    gKDR_=gKDR_method(W=g4data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=g4data, W_0=B), 
                    Wang=Wang_method(W=g4data, W_0=B), 
                    Ferr=Ferr_method(W=g4data, W_0=B))

Discrepancy_g6data  = c(Kernel=kernel_method(W=g6data, W_0=B),
                    gKDR_=gKDR_method(W=g6data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=g6data, W_0=B), 
                    Wang=Wang_method(W=g6data, W_0=B), 
                    Ferr=Ferr_method(W=g6data, W_0=B))

#gKDR -i
Discrepancy_gi2data = c(Kernel=kernel_method(W=gi2data, W_0=B),
                    gKDR_=gKDR_method(W=gi2data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gi2data, W_0=B), 
                    Wang=Wang_method(W=gi2data, W_0=B), 
                    Ferr=Ferr_method(W=gi2data, W_0=B))

Discrepancy_gi4data  = c(Kernel=kernel_method(W=gi4data , W_0=B),
                    gKDR_=gKDR_method(W=g4data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gi4data, W_0=B), 
                    Wang=Wang_method(W=gi4data, W_0=B), 
                    Ferr=Ferr_method(W=gi4data, W_0=B))

Discrepancy_gi6data  = c(Kernel=kernel_method(W=gi6data, W_0=B),
                    gKDR_=gKDR_method(W=gi6data, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gi6data, W_0=B), 
                    Wang=Wang_method(W=gi6data, W_0=B), 
                    Ferr=Ferr_method(W=gi6data, W_0=B))


#gKDR -v
Discrepancy_gv2data = c(Kernel=kernel_method(W=gv1_r, W_0=B),
                    gKDR_=gKDR_method(W=gv1_r, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gv1_r, W_0=B), 
                    Wang=Wang_method(W=gv1_r, W_0=B), 
                    Ferr=Ferr_method(W=gv1_r, W_0=B),
                    Pal=Relative_error(W=gv1_r, W_0=B))

Discrepancy_gv4data= c(Kernel=kernel_method(W=gv2_r, W_0=B),
                    gKDR_=gKDR_method(W=gv2_r, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gv2_r, W_0=B), 
                    Wang=Wang_method(W=gv2_r, W_0=B), 
                    Ferr=Ferr_method(W=gv2_r, W_0=B),
                    Pal=Relative_error(W=gv2_r, W_0=B))

Discrepancy_gv6data = c(Kernel=kernel_method(W=gv3_r, W_0=B),
                    gKDR_=gKDR_method(W=gv3_r, W_0=B), 
                    Li=Li_and_Chiaromonte_method(W=gv3_r, W_0=B), 
                    Wang=Wang_method(W=gv3_r, W_0=B), 
                    Ferr=Ferr_method(W=gv3_r, W_0=B),
                    Pal=Relative_error(W=gv3_r, W_0=B))



print("PCA")
Discrepancy_PCA1
Discrepancy_PCA2
Discrepancy_PCA3

Discrepancy_PCA4
Discrepancy_PCA5
Discrepancy_PCA6

print("PLS")
Discrepancy_PLS1
Discrepancy_PLS2
Discrepancy_PLS3



print("AS")
Discrepancy_AS1
Discrepancy_AS2
Discrepancy_AS3



print("gKDR with D=1")
Discrepancy_g2data
Discrepancy_g4data
Discrepancy_g6data


print("gKDRi with D=1")
Discrepancy_gi2data
Discrepancy_gi4data
Discrepancy_gi6data


print("gKDRv with D=1")
Discrepancy_gv2data
Discrepancy_gv4data
Discrepancy_gv6data




```




```{r}

# GP Performance Metrics
set.seed(1000)

counter=0

tic <- proc.time()[3]
pcaSr2= DimRed(X=resultsPCA2$x[,1:8], y=Data2$datatrain[, 11] %>% as.matrix(), 
               XX=Data2$datatest[,-11] %>% as.matrix() %*% resultsPCA2$rotation[, 1:8], 
               yytrue=Data2$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic

tic <- proc.time()[3]
pcaSr4= DimRed(X=resultsPCA4$x[,1:8], y=Data4$datatrain[, 11] %>% as.matrix(), 
               XX=Data4$datatest[,-11] %>% as.matrix() %*% resultsPCA4$rotation[, 1:8], 
               yytrue=Data4$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
pcaSr6= DimRed(X=resultsPCA6$x[,1:8], y=Data6$datatrain[, 11] %>% as.matrix(), 
               XX=Data6$datatest[,-11] %>% as.matrix() %*% resultsPCA6$rotation[, 1:8], 
               yytrue=Data6$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
pcaS2r2= DimRed(X=resultsPCA2$x[,1:2], y=Data2$datatrain[, 11] %>% as.matrix(), 
                XX=Data2$datatest[,-11] %>% as.matrix() %*% resultsPCA2$rotation[, 1:2], 
                yytrue=Data2$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
pcaS2r4= DimRed(X=resultsPCA4$x[,1:2], y=Data4$datatrain[, 11] %>% as.matrix(), 
                XX=Data4$datatest[,-11] %>% as.matrix() %*% resultsPCA4$rotation[, 1:2], 
                yytrue=Data4$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
pcaS2r6= DimRed(X=resultsPCA6$x[,1:2], y=Data6$datatrain[, 11] %>% as.matrix(), 
                XX=Data6$datatest[,-11] %>% as.matrix() %*% resultsPCA6$rotation[, 1:2], 
                yytrue=Data6$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
plsr2=DimRed(X=simPls2$scores[, 1]  %>% as.matrix(), 
             y=Data2$datatrain[, 11]  %>% as.matrix(), 
             XX=Data2$datatest[,-11] %>% as.matrix() %*% simPls2$projection[, 1], 
             yytrue=Data2$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
plsr4=DimRed(X=simPls4$scores[, 1]  %>% as.matrix() , 
             y=Data4$datatrain[, 11]  %>% as.matrix(), 
             XX=Data4$datatest[,-11] %>% as.matrix() %*% simPls4$projection[, 1], 
             yytrue=Data4$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
plsr6=DimRed(X=simPls6$scores[, 1]  %>% as.matrix(), 
             y=Data6$datatrain[, 11]  %>% as.matrix(), 
             XX=Data6$datatest[,-11] %>% as.matrix() %*% simPls6$projection[, 1], 
             yytrue=Data6$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic





tic <- proc.time()[3]
actr2=DimRed(X=X22 %>% as.matrix() %*% W2[, 1], 
             y=Data2$datatrain[, 11] %>% as.matrix(), 
             XX=Data2$datatest[,-11] %>% as.matrix() %*% W2[, 1], 
             yytrue=Data2$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic

tic <- proc.time()[3]
actr4=DimRed(X=X44 %>% as.matrix() %*% W4[, 1], 
             y=Data4$datatrain[, 11] %>% as.matrix(), 
             XX=Data4$datatest[,-11] %>% as.matrix() %*% W4[, 1], 
             yytrue=Data4$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic

tic <- proc.time()[3]
actr6=DimRed(X=X66 %>% as.matrix() %*% W6[, 1], 
             y=Data6$datatrain[, 11] %>% as.matrix(), 
             XX=Data6$datatest[,-11] %>% as.matrix() %*% W6[, 1], 
             yytrue=Data6$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic




tic <- proc.time()[3]
gr2= DimRed(X=Data2$datatrain[, -11] %>% as.matrix() %*% g2data, 
            y=Data2$datatrain[, 11] %>% as.matrix(), 
            XX=Data2$datatest[,-11] %>% as.matrix() %*% g2data, 
            yytrue=Data2$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gr4= DimRed(X=Data4$datatrain[, -11] %>% as.matrix() %*% g4data, 
            y=Data4$datatrain[, 11] %>% as.matrix(), 
            XX=Data4$datatest[,-11] %>% as.matrix() %*% g4data, 
            yytrue=Data4$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gr6= DimRed(X=Data6$datatrain[, -11] %>% as.matrix() %*% g6data, 
            y=Data6$datatrain[, 11] %>% as.matrix(), 
            XX=Data6$datatest[,-11] %>% as.matrix() %*% g6data, 
            yytrue=Data6$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gir2= DimRed(X=Data2$datatrain[, -11] %>% as.matrix() %*% gi2data, 
             y=Data2$datatrain[, 11] %>% as.matrix(), 
             XX=Data2$datatest[,-11] %>% as.matrix() %*% gi2data, 
             yytrue=Data2$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic

tic <- proc.time()[3]
gir4= DimRed(X=Data4$datatrain[, -11] %>% as.matrix() %*% gi4data, 
             y=Data4$datatrain[, 11] %>% as.matrix(), 
             XX=Data4$datatest[,-11] %>% as.matrix() %*% gi4data, 
             yytrue=Data4$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gir6= DimRed(X=Data6$datatrain[, -11] %>% as.matrix() %*% gi6data, 
             y=Data6$datatrain[, 11] %>% as.matrix(), 
             XX=Data6$datatest[,-11] %>% as.matrix() %*% gi6data, 
             yytrue=Data6$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gvr2= DimRed(X=Data2$datatrain[, -11] %>% as.matrix() %*% gv2data, 
             y=Data2$datatrain[, 11] %>% as.matrix(), 
             XX=Data2$datatest[,-11] %>% as.matrix() %*% gv2data, 
             yytrue=Data2$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gvr4= DimRed(X=Data4$datatrain[, -11] %>% as.matrix() %*% gv4data, 
             y=Data4$datatrain[, 11] %>% as.matrix(), 
             XX=Data4$datatest[,-11] %>% as.matrix() %*% gv4data, 
             yytrue=Data4$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic

tic <- proc.time()[3]
gvr6= DimRed(X=Data6$datatrain[, -11] %>% as.matrix() %*% gv6data, 
             y=Data6$datatrain[, 11] %>% as.matrix(), 
             XX=Data6$datatest[,-11] %>% as.matrix() %*% gv6data, 
             yytrue=Data6$yytrue%>% as.matrix())
toc <- proc.time()[3]
toc - tic


pcaSr2
pcaSr4
pcaSr6


pcaS2r2
pcaS2r4
pcaS2r6




plsr2
plsr4
plsr6


actr2
actr4
actr6


gr2
gr4
gr6


gir2
gir4
gir6

gvr2
gvr4
gvr6



tic <- proc.time()[3]
gv1= DimRed(X=Data2$datatrain[, -11] %>% as.matrix() %*% gv1_r, 
             y=Data2$datatrain[, 11] %>% as.matrix(), 
             XX=Data2$datatest[,-11] %>% as.matrix() %*% gv1_r, 
             yytrue=Data2$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gv2= DimRed(X=Data4$datatrain[, -11] %>% as.matrix() %*% gv2_r, 
             y=Data4$datatrain[, 11] %>% as.matrix(), 
             XX=Data4$datatest[,-11] %>% as.matrix() %*% gv2_r, 
             yytrue=Data4$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic


tic <- proc.time()[3]
gv3= DimRed(X=Data6$datatrain[, -11] %>% as.matrix() %*% gv3_r, 
             y=Data6$datatrain[, 11] %>% as.matrix(), 
             XX=Data6$datatest[,-11] %>% as.matrix() %*% gv3_r, 
             yytrue=Data6$yytrue %>% as.matrix())
toc <- proc.time()[3]
toc - tic

gv1
gv2
gv3


```












